{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FASTAI Lesson - 4 \n",
    "##Neural Net on MNIST dataset to recognize the digit in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will help us in plotting using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing Fastai libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to download the dataset and then saving it in the path location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/mnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are creating a folder where we are going to save the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL='http://deeplearning.net/data/mnist/'\n",
    "FILENAME='mnist.pkl.gz'\n",
    "\n",
    "def load_mnist(filename):\n",
    "    return pickle.load(gzip.open(filename, 'rb'), encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pickle and feather_format are both used for loading the python object but feather_format is much more optimal as compare to \n",
    "##pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data(URL+FILENAME, path+FILENAME)\n",
    "((x,y), (x_valid, y_valid), _) = load_mnist(path+FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Image from the mnist dataset are of 28*28 pixels but they as we load it, get flattened by the numpy for the further processing\n",
    "##That is why the dimension of the x is 50000, 784 (784 = 28*28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (50000, 784))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (50000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y), y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##As we know that machine learning algorithms works better when the data is normalized which means the mean of data is 0 and \n",
    "##standard_deviation is 1. For this we are going to normalize the data. We are going to substract the mean from each x value \n",
    "##and then divide the same by the standard deviation. So we are normalizing the image pixel by pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x.mean()\n",
    "std = x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13044983, 0.3072898, -3.1638146e-07, 0.99999934)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (x-mean)/std\n",
    "mean, std, x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since we have normalize our training data so now we have to do the same with validation data but with the same mean and std\n",
    "##value. So that we can can get equally normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.005850922, 0.99243325)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid = (x_valid - mean)/std\n",
    "x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So we have 10000 thousand images in the validation setof 28*28 pixels.\n",
    "##Now we are going to visualize the same but for this we have to deflatten the data.\n",
    "##For this purpose we are going to use reshape function. We normally left the one dimension as -1 because it will calculate by\n",
    "##itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img = np.reshape(x_valid, (-1, 28, 28))\n",
    "x_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining the show function so that we can visualize the data from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(x_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This shows that the prediction of our neural net for the above image should be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to do the slicing for this we are going to take some columns from 1st image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42452, -0.42452, -0.42452, -0.42452,  0.17294],\n",
       "       [-0.42452, -0.42452, -0.42452,  0.78312,  2.43567],\n",
       "       [-0.42452, -0.27197,  1.20261,  2.77889,  2.80432],\n",
       "       [-0.42452,  1.76194,  2.80432,  2.80432,  1.73651],\n",
       "       [-0.42452,  2.20685,  2.80432,  2.80432,  0.40176]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img[0,10:15,10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So we are flattening the data once again into two dimension and then we are picking up the rows from 10 to 14 and columns\n",
    "##from 10 to 14 and then we are plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(x_img[0,10:15,10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Below is for the 3-d representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.42452, -0.42452, -0.42452, -0.42452,  0.17294],\n",
       "        [-0.42452, -0.42452, -0.42452,  0.78312,  2.43567],\n",
       "        [-0.42452, -0.27197,  1.20261,  2.77889,  2.80432],\n",
       "        [-0.42452,  1.76194,  2.80432,  2.80432,  1.73651],\n",
       "        [-0.42452,  2.20685,  2.80432,  2.80432,  0.40176]],\n",
       "\n",
       "       [[ 2.52465, -0.04316, -0.42452, -0.42452, -0.42452],\n",
       "        [ 2.7916 ,  2.29584, -0.05587, -0.42452, -0.42452],\n",
       "        [ 1.7238 ,  2.7916 ,  2.33397, -0.10672, -0.42452],\n",
       "        [-0.25926,  2.00346,  2.80432,  2.34669,  1.26617],\n",
       "        [-0.42452, -0.24655,  1.38058,  2.80432,  2.7916 ]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img[0:2,10:15,10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        ...,\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452]],\n",
       "\n",
       "       [[-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        ...,\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452]],\n",
       "\n",
       "       [[-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        ...,\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        ...,\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452]],\n",
       "\n",
       "       [[-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        ...,\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452]],\n",
       "\n",
       "       [[-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        ...,\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452],\n",
       "        [-0.42452, -0.42452, -0.42452, ..., -0.42452, -0.42452, -0.42452]]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Taking the top 8 images from the validation set along with their y values and the below function is for plotting purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=2, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(x_img[:8], titles=y_valid[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALAAAAFlCAYAAABLM2J2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABQ9JREFUeJzt3KFNdFkAhuF7CZIg/wYoAIXGUQAZj6ABDA5D6IEmBpqgAiwJCgQJTdxtgD/L7s7M+V/2eeQV5xvx5ogRZ16WZYKqvdE/AP4LAZMmYNIETJqASRMwafvbOHSeZ//N/VDHx8dDdp+fn+evvruBSRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkbeVxP7bv4uJiyO7d3d2Q3d9xA5MmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaT/qdcqDg4Mhu9fX1zvfvLm52fnmNE3T3t6fdef9Wb8G/iEBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRM2rwsy+YPnefNH/oNj4+PI2an8/PzIbsjPDw8DNldrVbzV9/dwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRM2v7oH7BJR0dHo3/Cj3d/fz9kd7VaffndDUyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApM3Lsoz+DfCvuYFJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmLT9bRz6+fk55MnLk5OTEbPT29vbkN3/k2VZ5q++u4FJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKTNy7L5d/iWbRz6DS8vLyNmp7Ozs51vvr+/73xzJI/78SMJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRMmoBJEzBpAiZNwKQJmDQBkyZg0gRM2lZep1yv10Nep1ytViNmp9fX151vnp6e7nxzmqbp4+NjyK7XKfmRBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGn72zj08vJyG8f+rV+/fg3ZHfHQ3tPT0843p2ma1uv1kN3fcQOTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGnzsiybP3SeN3/oNxweHo6YnW5vb3e+eXV1tfPNaZqmbfTyHfM8z199dwOTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGkCJk3ApAmYNAGTJmDSBEyagEkTMGlbeZ0SdsUNTJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZMmYNIETJqASRMwaQImTcCkCZg0AZP2F+2kXPSjiEB5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(x_img[0:2,10:15,10:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to use Pytorch for building the neural net. Pytorch is the replacement of numpy which make the use of GPUs.\n",
    "##Now we are going to import all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to import the torch neural net library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to create a sequential neural network using the pytorch. \n",
    "##Sequential network is simplest neural net in pytorch and it will have the layers in it.\n",
    "##So the first layer in it is Linear Layer which is y=ax+b. Here this will do the matrix product and input to it is 28*28\n",
    "##pixel image and the output will be vector of size 10. \n",
    "##Next layer is non-linear layer which is LogSoftmax() layer. \n",
    "##.cuda() is for tell the pytorch to run this on GPU otherwise it will run on CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(28*28,10), nn.LogSoftmax()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to model the data object which wraps the training data, testing data and validation data together.\n",
    "##md will return the data object which as wraps all the things and then we are going to fit the data object to the model.\n",
    "##nn.Linear() is basically doing the metrics multiplication.\n",
    "##Loss function will be less if we have a good accuracy in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ImageClassifierData.from_arrays(path, (x, y), (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to define the loss function, optimizing algorithm that we are going to use.\n",
    "##Here we are using Negative log likelihood loss function which is also known as cross entropy.\n",
    "##It is basically of two types - binary and categorical. Down below is the implementation of binaray loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y, p):\n",
    "    return np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##In acts 1 means cat and 0 means dog. Then we have predicted values like we are 90% sure that it is cat. 80% sure for \n",
    "##dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.164252033486018"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts = np.array([1, 0, 0, 1])\n",
    "preds = np.array([0.9, 0.1, 0.2, 0.8])\n",
    "binary_loss(acts, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FITTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "metrics = [accuracy]\n",
    "opt = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to fit the data model.\n",
    "##net is the neural net that we have built.\n",
    "##md here is the data object. \n",
    "##epoch means number of time we are going over the image in order to train the model\n",
    "##crit paramerter id for the loss function.\n",
    "##opt for the optimization that we are going to use.\n",
    "##metrics means the metrics that we want to print and here it is accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79484e0f7aa24232a54bba5f51f4f9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.313274   0.286768   0.9186    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.28677]), 0.9186]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(net, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##With this we are getting the accuracy around 91.5% alon with training set and validation set loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(net, md.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##10000 for the number of images in validation and 10 because for each image it is giving out the ten prediction.\n",
    "##Probability of that image is 1 and probability of that image is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.45909,  -4.78881,  -2.61524, ..., -12.97193,  -4.6343 , -11.484  ],\n",
       "       [-11.37519,  -7.71234,  -5.13008, ...,  -9.24396,  -0.05098,  -8.24528],\n",
       "       [ -4.47414, -12.2018 ,  -3.32254, ...,  -6.51105,  -9.02763,  -7.14141],\n",
       "       ...,\n",
       "       [ -8.09738,  -9.29592, -12.94251, ...,  -7.64305,  -3.85679,  -6.02204],\n",
       "       [ -2.9698 , -10.57907,  -4.50004, ...,  -6.70381,  -8.08165,  -6.54364],\n",
       "       [ -2.68676,  -9.10139,  -4.73225, ...,  -5.26603,  -0.21617,  -3.06969]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 6, 9, 6])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(axis=1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will grab the index of the max value across all the prediction for the first 5 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 6, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9186"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pre == y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will give the mean value of array and that array will have 1 if our prediction matches the actual value else 0.\n",
    "##Now we are going to visualize our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(x_img[:8], titles=pre[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating the neural network with the hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = nn.Sequential(\n",
    "    nn.Linear(28*28,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So we are having a Linear layer and non-linear layer which is RelU layer. In this all the -ve value becomes 0 and there\n",
    "##other types of RelU layer also such as normal ReLU, Leaky ReLU and elu. Then passing the data to the linear layer and\n",
    "##then using the final non-linear layer which is log softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(net1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0280e45f763b41f5847f573f9de6ab6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.182224   0.154253   0.9581    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.15425]), 0.9581]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(net1, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now as we can see that adding the hidden layer will increase the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnet = nn.Sequential(\n",
    "    nn.Linear(28*28,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "metrics = [accuracy]\n",
    "opt = optim.SGD(dnet.parameters(), 1e-1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68e5ffb890b40e9995d42559ad6221a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.267927   0.285833   0.9237    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.28583]), 0.9237]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(dnet, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Increasing the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b9ea90c79349f2a30346931b87d825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.301076   0.25604    0.9368    \n",
      "    1      0.240112   0.232114   0.949                        \n",
      "    2      0.222613   0.204062   0.9556                       \n",
      "    3      0.184363   0.204158   0.9548                       \n",
      "    4      0.196734   0.257004   0.9538                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.257]), 0.9538]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(dnet, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Learning Rate Annealing means as the number of epoch increases decrease the leaning rate so that our model can fit\n",
    "##better and increases out accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff4e79b0f944c989c80d9fde3f4e3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      0.076254   0.150017   0.9676    \n",
      "    1      0.053239   0.144152   0.9698                        \n",
      "    2      0.056758   0.145026   0.97                          \n",
      "    3      0.044919   0.144202   0.9711                        \n",
      "    4      0.05022    0.143906   0.9716                        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.14391]), 0.9716]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(dnet, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To see the dimension of all the tensor which is used as parameters in neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78400, 100, 10000, 100, 1000, 10]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [o.numel() for o in dnet.parameters()]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So the 1st layer tensor size 784 * 100 (28*28*100) input to the first layer and its bias is 100.\n",
    "##For 2nd layer tensor size 100 * 100  input to the second layer and its bias is 100.\n",
    "##For 3rd layer tensor size 100 * 10 input to the third layer and its bias is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89610"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Total size is\n",
    "sum(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This might lead to the overfitting of data. So to overcome this we make the use of regularization. Most common regular-\n",
    "##-ization is l2 regularization.\n",
    "##In regularization we are going to impose penalty on paramter for not being zero.\n",
    "##If my training loss > validation loss then we are underfitting. So there is no point of regularization.\n",
    "##This is very good for modern machine learning to overparameterized data and then use regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnet = nn.Sequential(\n",
    "    nn.Linear(28*28,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is with the regularization weight decay is parameter for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "metrics = [accuracy]\n",
    "opt = optim.SGD(dnet.parameters(), 1e-1, momentum=0.9, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1565ae0c5c34adb9a1ca0c2ee338075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.2626     0.268021   0.9237    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.26802]), 0.9237]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(dnet, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0436e324de4c8f8b7046602679a60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      0.092474   0.102774   0.9704    \n",
      "    1      0.081489   0.09635    0.9725                        \n",
      "    2      0.065877   0.088129   0.9747                        \n",
      "    3      0.065698   0.086782   0.9747                        \n",
      "    4      0.049171   0.08137    0.9767                        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.08137]), 0.9767]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(dnet, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING OUR NEURAL NET LAYERS FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So we got 1 worng answer in first 8 images. So till now we have created only 1 layer of logistic regression till now.\n",
    "##Now we are going to implement the logistic regression (nn.Linear) from scratch without using any layer. \n",
    "##For this we are going to implement the pytorch class which will inherit something from the super class nn.Module.\n",
    "##Below class is the Module of pytorch which can be neuralnet or a layer in neuralnet.\n",
    "##When you initialize the inherit class you also need to initialize the base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8031  0.5418 -0.5479  1.5135\n",
       "-1.0547 -0.6422  0.5780 -0.8421\n",
       "-1.1819  0.6323 -1.5566 -0.2214\n",
       "[torch.cuda.FloatTensor of size 3x4 (GPU 0)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3,4).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will return the tensor of random number.\n",
    "def get_weights(*dims): return nn.Parameter(torch.randn(dims)/dims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0880\n",
       "-0.1547\n",
       " 0.0097\n",
       "-0.0300\n",
       " 0.2668\n",
       " 0.0711\n",
       "-0.0629\n",
       " 0.0470\n",
       "-0.0339\n",
       " 0.0169\n",
       "[torch.cuda.FloatTensor of size 10 (GPU 0)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_weights(10).cuda()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "##In forward function we are reshaping the input data. Means we are flattening it. x.size(0) will return the number of \n",
    "##images in dataset and then it will flatten it. After that it will multiply the tensor with the 28*28, 10 dimension\n",
    "##tensor with random number and then adding the bias and then applying the softmax function.\n",
    "##matmul is used for matrix multiplication\n",
    "##softmax function gives us the probability which is very easy for the neural network to learn from it. softmax is good\n",
    "##for the categorical prediction but for multilabel prediction we use sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1_w = get_weights(28*28,10) ##layer 1 weight with input 28*28 and gives output of 10 size\n",
    "        self.l1_b = get_weights(10)  ##layer 1 bias of size 10.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.matmul(x, self.l1_w) + self.l1_b\n",
    "        x = torch.log(torch.exp(x)/torch.exp(x).sum(dim=0))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now deploying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = LogReg().cuda()\n",
    "opt = optim.Adam(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "##.parameters() is the thing which pytorch is going to optimize and so pytorch look for something with datatype Parameter\n",
    "##Here in our case get_weight has a variable with datatype nn.Parameter which create a tensor of random numbers. \n",
    "##So pytorch will try to optimize it.\n",
    "##Fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99157ad74c5473da1addfcb6109008d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      2.460336   2.409594   0.9089    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.40959]), 0.9089]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(net2, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "##We are getting almost same accuracy. Till now we have built the simplest nerual network using the logistic regression\n",
    "##without any hidden layer. Now we are going to build everything from scratch just like above with the help pytorch.\n",
    "##We use pytorch because it give us ability to run any code on GPU just by adding .cuda() in the end and it automatically\n",
    "##differentiate the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now as we know that md is our dataobject it contain all the image data. So we are going to make it iterator and ask it\n",
    "##again and again to return the images from complete data. It will always return the image in the batch size of 64 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = iter(md.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmb, ymb = next(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "          ...             â‹±             ...          \n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "[torch.cuda.FloatTensor of size 64x784 (GPU 0)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is the first batch of 64 images and here the most pixels are not zero due to the normalization thing.\n",
    "##Now we are going to take the variable of our data which is new datatype in pytorch which is the superset of tensor.\n",
    "##Variable is used to keep the track of all the operations that we have done on tensor so that it can used during the\n",
    "##derivation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "          ...             â‹±             ...          \n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "-0.4245 -0.4245 -0.4245  ...  -0.4245 -0.4245 -0.4245\n",
       "[torch.cuda.FloatTensor of size 64x784 (GPU 0)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmp = Variable(xmb.cuda())\n",
    "vmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are predicting the values and .exp() because in the end of softmax function we are taking the log of values.\n",
    "##So to neutralize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 5 \n",
       " 3.1334e-01  4.0231e-08  1.6148e-04  1.7287e-03  6.0400e-06  1.9477e-03\n",
       " 2.0093e-05  1.8872e-06  5.5584e-06  2.4495e-04  2.7396e-04  2.3885e-04\n",
       " 5.8590e-04  1.2963e-01  1.0548e-02  1.2004e-02  3.9168e-04  2.8242e-03\n",
       " 1.4763e-03  1.1427e-03  4.8672e-02  4.1322e-03  2.2583e-04  5.3069e-05\n",
       " 1.0576e-02  1.3842e-05  3.1363e-03  4.4513e-03  2.3346e-03  2.8389e-03\n",
       " 3.9345e-03  3.9868e-04  1.5515e-03  9.4996e-03  1.1349e-02  5.6681e-03\n",
       " 7.3423e-04  8.8394e-05  3.1289e-03  6.7507e-04  1.3732e-03  1.1786e-03\n",
       " 9.5900e-05  5.3022e-04  4.1937e-04  1.1740e-03  5.7605e-03  8.8609e-05\n",
       " 9.0597e-06  1.2557e-07  5.6824e-05  4.8878e-05  7.7532e-05  6.7731e-07\n",
       " 1.0905e-03  4.9074e-04  1.5303e-03  1.2376e-03  1.9169e-03  6.7520e-04\n",
       " 4.4442e-04  1.0164e-01  7.7699e-03  1.0697e-02  7.2343e-03  1.3353e-03\n",
       " 1.1183e-02  2.4779e-05  5.1837e-03  6.8729e-04  8.1139e-03  5.1896e-04\n",
       " 6.2436e-05  1.4105e-01  6.9952e-03  3.1727e-02  2.5345e-03  1.0464e-02\n",
       " 3.7222e-04  7.8935e-02  6.5298e-03  5.6745e-03  5.0386e-04  1.6907e-03\n",
       " 1.0555e-01  8.3068e-07  1.2022e-04  1.2800e-03  3.5786e-04  3.8945e-02\n",
       " 1.2022e-03  1.5918e-05  5.1559e-04  4.5408e-03  1.3810e-03  1.0007e-03\n",
       " 2.0754e-05  3.8227e-06  3.1577e-03  5.9897e-05  5.4180e-04  4.6278e-04\n",
       " 1.0757e-04  6.4467e-04  6.2903e-03  2.0356e-03  1.2544e-02  7.8187e-04\n",
       " 1.5970e-05  7.5486e-07  3.7881e-04  4.0769e-03  1.2285e-02  4.8160e-04\n",
       " 3.4543e-03  1.2963e-05  2.2797e-03  2.5591e-02  2.3819e-03  8.3398e-04\n",
       " 6.1358e-02  2.4714e-07  4.5421e-03  3.2427e-03  7.7370e-04  6.3187e-04\n",
       " 5.1937e-05  3.3491e-08  1.6644e-02  2.8416e-02  2.4155e-05  1.0266e-04\n",
       " 3.7775e-03  4.5512e-04  3.0436e-03  3.7557e-02  1.6841e-02  1.7378e-01\n",
       " 6.0494e-03  6.0537e-06  1.3469e-03  8.5955e-04  3.7418e-04  2.9874e-03\n",
       " 7.8506e-06  1.7637e-03  8.1592e-06  2.3354e-04  1.1835e-03  9.3653e-04\n",
       " 3.4638e-03  2.3325e-03  3.0944e-03  2.3258e-03  3.7359e-03  7.0908e-03\n",
       " 1.8760e-04  4.3336e-05  8.4327e-05  1.3073e-03  5.9851e-03  2.9988e-04\n",
       " 8.7116e-05  5.5215e-06  6.0375e-04  2.1152e-03  4.0140e-04  1.3675e-04\n",
       " 5.5688e-04  1.3236e-03  8.5657e-03  2.5974e-03  1.1619e-01  5.3466e-04\n",
       " 5.2267e-05  3.2646e-03  1.5837e-03  1.7709e-02  1.1825e-03  2.5230e-04\n",
       " 1.6996e-04  5.0479e-04  3.1871e-02  5.8380e-03  1.2545e-02  6.9279e-03\n",
       " 6.7535e-03  8.3028e-02  1.7150e-02  1.1216e-02  3.9091e-03  5.9958e-03\n",
       " 2.2896e-05  1.1900e-01  5.6146e-03  8.6737e-03  9.6666e-04  3.3224e-04\n",
       " 5.2324e-03  3.3892e-05  1.9667e-02  1.8321e-03  9.3730e-04  6.5320e-04\n",
       " 2.4237e-03  2.1092e-09  2.5866e-02  1.3718e-02  1.3215e-04  1.9478e-04\n",
       " 2.6508e-03  5.6216e-05  5.8256e-04  2.7569e-03  1.5364e-03  1.1167e-01\n",
       " 3.4026e-04  4.3338e-05  1.0889e-04  1.8887e-03  1.4807e-02  6.1498e-04\n",
       " 2.7661e-03  1.2840e-04  3.5193e-04  2.0024e-04  1.3818e-02  4.0141e-02\n",
       " 1.5899e-04  1.2477e-02  3.2155e-03  1.2892e-02  2.4327e-03  1.1724e-03\n",
       " 2.7474e-03  7.5390e-02  3.6193e-03  1.4493e-02  1.2950e-03  1.0365e-02\n",
       " 1.6903e-04  2.2742e-04  2.0804e-03  2.6040e-04  3.1721e-03  1.0276e-03\n",
       " 3.2311e-05  4.2247e-03  1.6029e-04  1.3760e-02  2.8186e-02  2.2363e-03\n",
       " 7.2044e-05  1.6689e-06  3.1386e-04  2.9662e-01  2.2997e-05  3.0831e-04\n",
       " 2.8632e-03  1.8071e-03  9.0839e-04  9.5144e-04  2.9779e-02  3.1593e-03\n",
       " 1.5032e-03  1.0709e-05  2.2097e-04  2.2639e-03  7.2673e-03  1.6256e-03\n",
       " 2.3718e-04  1.0691e-01  1.0784e-02  6.9251e-02  7.8003e-03  2.0917e-02\n",
       " 7.7310e-03  3.0354e-04  1.4501e-04  1.6367e-03  5.9989e-04  1.6263e-01\n",
       " 3.1200e-01  1.3302e-07  8.4272e-04  2.9418e-03  1.4272e-04  1.7888e-02\n",
       " 7.9195e-04  8.7648e-07  2.0432e-04  1.6105e-04  3.2130e-03  5.8238e-04\n",
       " 1.2998e-03  2.9736e-05  2.3961e-03  1.1788e-03  6.9526e-04  1.5565e-03\n",
       " 2.2909e-04  3.8617e-05  6.3740e-05  2.7126e-03  2.2724e-02  1.1131e-03\n",
       " 2.3344e-04  1.4257e-05  6.0187e-04  6.7575e-04  2.1413e-02  2.7193e-04\n",
       " 3.0471e-04  1.0931e-05  9.2040e-03  6.6494e-02  1.5290e-03  1.8030e-03\n",
       " 1.0397e-03  1.6725e-03  1.5952e-02  7.2870e-02  1.1635e-03  2.2254e-02\n",
       " 3.0230e-04  4.8220e-08  3.5661e-03  3.2995e-06  8.4410e-03  2.2759e-05\n",
       " 1.4287e-03  3.1376e-06  3.3055e-06  9.5254e-03  2.7972e-05  6.6023e-02\n",
       " 1.8559e-02  4.7067e-06  1.2790e-03  8.0169e-02  3.8996e-05  1.0105e-02\n",
       " 6.1695e-04  1.2909e-01  1.2718e-02  9.6606e-03  1.0703e-03  1.5519e-03\n",
       " 5.6729e-03  6.5137e-04  4.0123e-03  5.4391e-02  1.2200e-02  1.2746e-01\n",
       " 1.5488e-02  2.6402e-04  5.0000e-04  1.7048e-02  1.4703e-03  1.2003e-01\n",
       " 7.4434e-02  3.7423e-06  9.1679e-04  2.1589e-03  2.3953e-05  1.3182e-04\n",
       " 5.7908e-04  1.9559e-04  4.9307e-04  2.0749e-04  5.6640e-01  3.9638e-04\n",
       " 4.2914e-06  6.0493e-05  2.9140e-05  7.5366e-04  1.1953e-02  2.1040e-05\n",
       " 1.2764e-03  2.8303e-06  6.7661e-01  2.8651e-03  3.6540e-06  3.0085e-05\n",
       "\n",
       "Columns 6 to 9 \n",
       " 2.2860e-05  2.3501e-06  6.5505e-04  1.1109e-05\n",
       " 5.2236e-07  9.3539e-02  1.3090e-03  7.6722e-03\n",
       " 1.9066e-03  2.1942e-04  9.8926e-03  8.3403e-04\n",
       " 6.3913e-06  2.3794e-02  4.9890e-03  5.2933e-03\n",
       " 6.9998e-06  1.0815e-01  1.6230e-03  1.6957e-03\n",
       " 8.0035e-04  4.9764e-02  6.4878e-04  2.2397e-02\n",
       " 1.6116e-01  3.7441e-05  1.9025e-04  4.8877e-05\n",
       " 9.3539e-05  1.8399e-02  1.2809e-03  5.9823e-02\n",
       " 3.4727e-05  1.2127e-05  1.3451e-01  3.7552e-04\n",
       " 4.1853e-05  6.0332e-02  5.9217e-04  2.8771e-03\n",
       " 2.8836e-03  4.0637e-03  1.9573e-03  2.0746e-03\n",
       " 1.2773e-04  1.9315e-04  3.5535e-02  3.4825e-03\n",
       " 3.7057e-03  9.7018e-05  9.8226e-03  4.2662e-04\n",
       " 8.1001e-04  1.2595e-03  6.4862e-03  4.4217e-03\n",
       " 4.7671e-05  1.1301e-04  1.4591e-03  3.8423e-04\n",
       " 8.0838e-06  4.9836e-02  3.8262e-03  3.8620e-02\n",
       " 2.2039e-01  7.5349e-07  8.7348e-05  1.8474e-06\n",
       " 1.3022e-04  1.2988e-01  2.7509e-03  7.2691e-03\n",
       " 1.0898e-05  3.8152e-03  2.5004e-03  1.6380e-01\n",
       " 1.5118e-05  8.1829e-02  8.4808e-04  1.8048e-02\n",
       " 1.2184e-02  4.0892e-04  2.8017e-04  8.4309e-05\n",
       " 2.0940e-07  1.8815e-07  9.9510e-02  6.5336e-06\n",
       " 1.2228e-04  5.8926e-05  1.3814e-02  8.7190e-04\n",
       " 7.0930e-02  2.1000e-06  9.2707e-05  4.8263e-06\n",
       " 1.3780e-05  6.3142e-02  1.7229e-03  4.1506e-02\n",
       " 2.4665e-04  7.6580e-04  2.4092e-02  2.3319e-03\n",
       " 6.2368e-05  6.6248e-03  9.5281e-04  8.6580e-02\n",
       " 1.0848e-06  8.6312e-02  1.2067e-03  1.4423e-02\n",
       " 1.9522e-02  2.3063e-03  1.8741e-03  2.1959e-03\n",
       " 7.2413e-06  1.0460e-01  1.3960e-03  3.2559e-02\n",
       " 6.4377e-04  2.2820e-05  8.7859e-02  1.7084e-03\n",
       " 1.1397e-03  3.1881e-04  9.4628e-03  2.2894e-04\n",
       " 2.5748e-03  5.8195e-04  3.2134e-03  2.1826e-03\n",
       " 3.1852e-04  7.2822e-05  7.4499e-04  1.0320e-04\n",
       " 5.8542e-04  6.3668e-06  8.8159e-06  6.4703e-05\n",
       " 1.3887e-03  2.1741e-04  1.4385e-03  9.8381e-04\n",
       " 6.1490e-05  9.7494e-03  7.5428e-04  6.5958e-02\n",
       " 7.8769e-06  8.9883e-04  7.2909e-03  3.9531e-04\n",
       " 2.1577e-04  1.3352e-04  5.8754e-02  5.1010e-04\n",
       " 2.9387e-03  1.9935e-03  9.6070e-03  3.8924e-03\n",
       " 2.9773e-05  5.8155e-05  5.5218e-02  4.9433e-03\n",
       " 2.3407e-04  1.1006e-03  8.8929e-03  6.0429e-02\n",
       " 1.0276e-05  1.1581e-07  2.3747e-03  7.7278e-05\n",
       " 3.7657e-02  4.4062e-04  1.9474e-02  1.2311e-03\n",
       " 3.9102e-05  6.0156e-02  7.7624e-04  2.0424e-02\n",
       " 6.5639e-03  3.9613e-04  6.3332e-03  5.1140e-04\n",
       " 6.8504e-05  2.2335e-05  2.2522e-03  3.0351e-06\n",
       " 7.5050e-04  3.3689e-06  3.8451e-04  3.9953e-05\n",
       " 8.6626e-04  2.7655e-06  2.2141e-01  2.8001e-02\n",
       " 4.1285e-02  4.7424e-06  3.9380e-04  9.8209e-06\n",
       " 6.5308e-05  3.9218e-03  2.4353e-03  9.0643e-02\n",
       " 2.7728e-04  1.7780e-02  1.8123e-03  5.4596e-02\n",
       " 2.0952e-04  2.7838e-08  7.9942e-02  4.3509e-07\n",
       " 2.7333e-03  1.0432e-05  7.0548e-03  1.3364e-04\n",
       " 3.2520e-01  2.3252e-06  2.4259e-03  7.9497e-05\n",
       " 2.2875e-07  4.0439e-06  2.6996e-03  6.6553e-06\n",
       " 3.3350e-08  7.1048e-06  1.5716e-02  6.6112e-05\n",
       " 1.3152e-03  3.0016e-04  5.9701e-03  2.2799e-04\n",
       " 5.6403e-03  4.5036e-05  1.1600e-02  1.8341e-04\n",
       " 4.0240e-03  4.6551e-05  2.3956e-04  4.3343e-05\n",
       " 5.3611e-02  7.4272e-07  1.6388e-03  1.3026e-06\n",
       " 6.7154e-03  8.4907e-04  3.8104e-03  2.3746e-03\n",
       " 1.3786e-05  1.1296e-02  2.0239e-03  1.3983e-01\n",
       " 7.5186e-03  5.3123e-09  7.4101e-05  1.8252e-08\n",
       "[torch.cuda.FloatTensor of size 64x10 (GPU 0)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = net2(vmp).exp()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is actually the probability of 64 images each with 10 probabilities. Retriving the top3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 5 \n",
       " 3.1334e-01  4.0231e-08  1.6148e-04  1.7287e-03  6.0400e-06  1.9477e-03\n",
       " 2.0093e-05  1.8872e-06  5.5584e-06  2.4495e-04  2.7396e-04  2.3885e-04\n",
       " 5.8590e-04  1.2963e-01  1.0548e-02  1.2004e-02  3.9168e-04  2.8242e-03\n",
       "\n",
       "Columns 6 to 9 \n",
       " 2.2860e-05  2.3501e-06  6.5505e-04  1.1109e-05\n",
       " 5.2236e-07  9.3539e-02  1.3090e-03  7.6722e-03\n",
       " 1.9066e-03  2.1942e-04  9.8926e-03  8.3403e-04\n",
       "[torch.cuda.FloatTensor of size 3x10 (GPU 0)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 7\n",
       " 1\n",
       " 2\n",
       " 7\n",
       " 7\n",
       " 6\n",
       " 9\n",
       " 8\n",
       " 7\n",
       " 1\n",
       " 8\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 7\n",
       " 6\n",
       " 7\n",
       " 9\n",
       " 7\n",
       " 0\n",
       " 8\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 7\n",
       " 4\n",
       " 7\n",
       " 8\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 5\n",
       " 9\n",
       " 5\n",
       " 8\n",
       " 1\n",
       " 8\n",
       " 9\n",
       " 3\n",
       " 6\n",
       " 7\n",
       " 1\n",
       " 5\n",
       " 0\n",
       " 8\n",
       " 6\n",
       " 9\n",
       " 9\n",
       " 8\n",
       " 3\n",
       " 6\n",
       " 5\n",
       " 3\n",
       " 1\n",
       " 5\n",
       " 5\n",
       " 0\n",
       " 4\n",
       " 9\n",
       " 2\n",
       "[torch.cuda.LongTensor of size 64 (GPU 0)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Now to check the maximum probabilty across the 10 images. We are taking the index of maximum probability\n",
    "preds.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to visualize the Top 8 output from the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = predict(net2, md.val_dl).argmax(1)\n",
    "plots(x_img[:8], titles=preds[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So we get the good result but still one is incorrect. But now we are going to write matrix multiplication operator \n",
    "##from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Numpy elementary operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([4, 5, 6]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a < b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "##In Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  1\n",
       "  2\n",
       "  3\n",
       " [torch.cuda.LongTensor of size 3 (GPU 0)], \n",
       "  4\n",
       "  5\n",
       "  6\n",
       " [torch.cuda.LongTensor of size 3 (GPU 0)])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T([1,2,3])\n",
    "b = T([4,5,6])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 5\n",
       " 7\n",
       " 9\n",
       "[torch.cuda.LongTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.cuda.ByteTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a < b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Element wise operation doesn't need the for loop. And for loop in python is much slower than in C. Using the pytorch \n",
    "##tensor make the used of SIMD along with muliple core to boost the performance and running it on GPU make it 100x more\n",
    "##faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Broadcasting mean copying the value of my one or more axis in order to make it dimensionally equal to the other tensor\n",
    "##Broadcasting by scalar example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.cuda.LongTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 0\n",
       " 0\n",
       "[torch.cuda.ByteTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here a is rank1 tensor and 2 is rank0 tensor or scalar. So it will broadcast the value of rank0 tensor to make it rank1\n",
    "##tensor. Now scalar value is [2,2,2] and then it will do the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.cuda.LongTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Broadcasting a vector to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1,2,3], \n",
    "    [4,5,6],\n",
    "    [7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([10,20,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 22, 33],\n",
       "       [14, 25, 36],\n",
       "       [17, 28, 39]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here c is broadcasted into rank2 tensor from rank1 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30],\n",
       "       [10, 20, 30],\n",
       "       [10, 20, 30]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.broadcast_to(c, m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Above will tell you how the rank1 tensor get broadcasted for addition with m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [20],\n",
       "       [30]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30],\n",
       "       [10, 20, 30],\n",
       "       [10, 20, 30]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.broadcast_to(c[None], m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 10, 10],\n",
       "       [20, 20, 20],\n",
       "       [30, 30, 30]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.broadcast_to(c[:,None], m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 200, 300],\n",
       "       [200, 400, 600],\n",
       "       [300, 600, 900]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None] * c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So now we are going to make the use of broadcasting in order to built much more efficient matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m  ##rank2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c  ##rank1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140, 320, 500])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m @ c  ##1*10 + 2*20 + 3*30 = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This was for numpy. But for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 140\n",
       " 320\n",
       " 500\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.from_numpy(m), torch.from_numpy(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  40,  90],\n",
       "       [ 40, 100, 180],\n",
       "       [ 70, 160, 270]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "##But this is not matrix multiplication. This is element wise multiplication but using broadcasting.\n",
    "##See but if we will add each element across the rows then we get the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140, 320, 500])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m * c).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "##But the above is matrix multiplication but for the single columns. Now we will expand this for all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 40],\n",
       "       [20,  0],\n",
       "       [30, -5]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.array([[10,40],[20,0],[30,-5]])\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,  25],\n",
       "       [320, 130],\n",
       "       [500, 235]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m @ n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Doing the matrix multiplication for columns 1 and columns 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140, 320, 500])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m * n[:,0]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25, 130, 235])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m * n[:,1]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Integrating our "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb87624409fb4fa4bfe17c8c5e44a87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      2.460079   2.40538    0.9064    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.40538]), 0.9064]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our code from above\n",
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1_w = get_weights(28*28, 10)  # Layer 1 weights\n",
    "        self.l1_b = get_weights(10)         # Layer 1 bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x @ self.l1_w + self.l1_b \n",
    "        return torch.log(torch.exp(x)/torch.exp(x).sum(dim=0))\n",
    "\n",
    "net2 = LogReg().cuda()\n",
    "opt=optim.Adam(net2.parameters())\n",
    "\n",
    "fit(net2, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So till now we are using the fit() function. But now we are going to write our own training loop.\n",
    "##This loop will grab the mini-batch of data each time and then we pass it to the optimizer and then it will come with \n",
    "##slightly better prediction for this mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = LogReg().cuda()\n",
    "loss = nn.NLLLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(net2.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So to take the data from md in the form of mini-batch of 64 images we are going to do folllowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = iter(md.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For grabbing the data again and again we will use next() function and then we will predicted the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, yt = next(dl)\n",
    "preds = net2(Variable(xt).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-4.1400 -4.1333 -4.1161 -4.1346 -4.1376 -4.1350 -4.1313 -4.2016 -4.1291 -4.1660\n",
       "-4.1946 -4.1767 -4.2037 -4.1672 -4.1878 -4.1414 -4.1949 -4.1153 -4.1684 -4.1490\n",
       "-4.1384 -4.1425 -4.1780 -4.1830 -4.1893 -4.1518 -4.1490 -4.1741 -4.1334 -4.1702\n",
       "-4.1653 -4.1480 -4.1811 -4.1289 -4.1646 -4.1561 -4.1538 -4.1604 -4.1549 -4.2168\n",
       "-4.1717 -4.1640 -4.1686 -4.1745 -4.1600 -4.1536 -4.1504 -4.1425 -4.1766 -4.1684\n",
       "-4.1611 -4.2129 -4.1408 -4.1435 -4.1640 -4.1315 -4.2003 -4.1592 -4.1707 -4.1800\n",
       "-4.1803 -4.1717 -4.1679 -4.2227 -4.1571 -4.1710 -4.2250 -4.1460 -4.1613 -4.1687\n",
       "-4.1714 -4.1719 -4.1462 -4.1465 -4.1463 -4.1754 -4.2136 -4.1701 -4.1625 -4.1460\n",
       "-4.0928 -4.1701 -4.1559 -4.1543 -4.1416 -4.1946 -4.1693 -4.1666 -4.1554 -4.1691\n",
       "-4.1266 -4.1736 -4.2084 -4.1613 -4.1843 -4.1940 -4.1565 -4.1047 -4.1774 -4.1601\n",
       "-4.1407 -4.1661 -4.1840 -4.2095 -4.1553 -4.1616 -4.1295 -4.1689 -4.1724 -4.1302\n",
       "-4.1557 -4.1117 -4.1702 -4.1707 -4.1973 -4.1786 -4.1472 -4.1285 -4.1236 -4.1748\n",
       "-4.1825 -4.1377 -4.1735 -4.1391 -4.1455 -4.1518 -4.1794 -4.1509 -4.1383 -4.1471\n",
       "-4.1522 -4.1275 -4.1561 -4.2056 -4.1770 -4.1555 -4.2034 -4.1676 -4.1500 -4.1695\n",
       "-4.1692 -4.1853 -4.1337 -4.1680 -4.1844 -4.1310 -4.1514 -4.1030 -4.1611 -4.1212\n",
       "-4.1367 -4.0810 -4.1850 -4.1352 -4.1279 -4.1723 -4.1308 -4.1470 -4.1546 -4.2241\n",
       "-4.1482 -4.1797 -4.1364 -4.1567 -4.1335 -4.1724 -4.1575 -4.1970 -4.2197 -4.1524\n",
       "-4.1557 -4.1444 -4.1976 -4.1574 -4.1694 -4.1837 -4.1292 -4.1969 -4.1852 -4.1388\n",
       "-4.1982 -4.1176 -4.1457 -4.2591 -4.1907 -4.1831 -4.2299 -4.1837 -4.1620 -4.1547\n",
       "-4.1408 -4.1822 -4.1392 -4.1372 -4.1513 -4.1330 -4.1817 -4.1407 -4.1549 -4.1776\n",
       "-4.1576 -4.1503 -4.1445 -4.1805 -4.1742 -4.1646 -4.1214 -4.1672 -4.1682 -4.1401\n",
       "-4.1685 -4.1730 -4.1582 -4.1769 -4.1631 -4.1913 -4.1685 -4.1687 -4.1413 -4.1107\n",
       "-4.1309 -4.1689 -4.1811 -4.1347 -4.1585 -4.1782 -4.1347 -4.1765 -4.1004 -4.1747\n",
       "-4.1462 -4.1841 -4.1553 -4.1042 -4.1303 -4.1642 -4.2004 -4.1702 -4.1775 -4.1941\n",
       "-4.1871 -4.0826 -4.1516 -4.2348 -4.1680 -4.1946 -4.1686 -4.1516 -4.1796 -4.1447\n",
       "-4.1836 -4.2004 -4.2027 -4.1633 -4.1833 -4.1661 -4.1323 -4.1725 -4.2050 -4.1576\n",
       "-4.1128 -4.2170 -4.1678 -4.0831 -4.1273 -4.1508 -4.1910 -4.1586 -4.1791 -4.1981\n",
       "-4.1965 -4.1327 -4.1647 -4.1592 -4.1071 -4.1465 -4.1840 -4.2296 -4.1214 -4.1507\n",
       "-4.1669 -4.1421 -4.1485 -4.1726 -4.2182 -4.1438 -4.1460 -4.1427 -4.1764 -4.1285\n",
       "-4.1374 -4.1842 -4.1356 -4.1978 -4.1614 -4.1826 -4.0872 -4.1450 -4.2039 -4.1459\n",
       "-4.1412 -4.1517 -4.1075 -4.1611 -4.1227 -4.1579 -4.1687 -4.1669 -4.1623 -4.1963\n",
       "-4.1370 -4.1659 -4.1623 -4.1233 -4.1704 -4.1603 -4.1375 -4.1434 -4.1726 -4.1230\n",
       "-4.1646 -4.1185 -4.1398 -4.2127 -4.1565 -4.1721 -4.2031 -4.1688 -4.1774 -4.1707\n",
       "-4.1428 -4.1704 -4.1821 -4.1458 -4.1559 -4.1244 -4.1127 -4.1483 -4.1415 -4.1539\n",
       "-4.1370 -4.1498 -4.1812 -4.1081 -4.1246 -4.1507 -4.1484 -4.1732 -4.1908 -4.2089\n",
       "-4.1554 -4.1590 -4.1667 -4.1361 -4.1321 -4.1273 -4.1437 -4.1738 -4.1522 -4.1802\n",
       "-4.1742 -4.2152 -4.1512 -4.1342 -4.1341 -4.1569 -4.2196 -4.1733 -4.1324 -4.1290\n",
       "-4.1706 -4.1812 -4.2441 -4.1925 -4.1657 -4.1523 -4.0868 -4.1574 -4.1262 -4.1074\n",
       "-4.1550 -4.1865 -4.1671 -4.1555 -4.1546 -4.1839 -4.1636 -4.1492 -4.1669 -4.1269\n",
       "-4.1802 -4.1407 -4.1679 -4.1531 -4.1825 -4.1342 -4.1571 -4.1860 -4.1523 -4.1053\n",
       "-4.1371 -4.1624 -4.1543 -4.2140 -4.1945 -4.1486 -4.1831 -4.1284 -4.1570 -4.1205\n",
       "-4.1764 -4.1352 -4.1674 -4.1423 -4.1473 -4.1575 -4.1769 -4.1586 -4.1500 -4.1543\n",
       "-4.1698 -4.1713 -4.1471 -4.1438 -4.1584 -4.1563 -4.1772 -4.1264 -4.1296 -4.1145\n",
       "-4.1420 -4.1537 -4.1617 -4.1783 -4.1309 -4.1687 -4.1150 -4.1906 -4.1872 -4.1666\n",
       "-4.1370 -4.1760 -4.1954 -4.1458 -4.1661 -4.1696 -4.1166 -4.1109 -4.1602 -4.1400\n",
       "-4.1608 -4.1258 -4.1559 -4.1160 -4.2115 -4.1804 -4.1592 -4.1142 -4.1421 -4.1695\n",
       "-4.1515 -4.1525 -4.1377 -4.1300 -4.1153 -4.1460 -4.1301 -4.2174 -4.1884 -4.1737\n",
       "-4.1707 -4.1988 -4.1710 -4.1108 -4.1617 -4.1720 -4.2274 -4.1771 -4.2094 -4.2033\n",
       "-4.1388 -4.1605 -4.1648 -4.1636 -4.1679 -4.1520 -4.1474 -4.1708 -4.1187 -4.1860\n",
       "-4.1728 -4.1484 -4.1508 -4.1811 -4.1787 -4.1248 -4.1556 -4.1499 -4.1169 -4.1475\n",
       "-4.1525 -4.2008 -4.1204 -4.1603 -4.1263 -4.1342 -4.1696 -4.1494 -4.1546 -4.1505\n",
       "-4.1376 -4.1688 -4.1418 -4.1573 -4.1838 -4.1750 -4.1154 -4.1327 -4.1884 -4.1815\n",
       "-4.1941 -4.1410 -4.1083 -4.1901 -4.1333 -4.1308 -4.1844 -4.2046 -4.1568 -4.1718\n",
       "-4.1734 -4.1593 -4.1706 -4.1552 -4.1715 -4.1618 -4.1617 -4.1330 -4.1357 -4.1317\n",
       "-4.1785 -4.1497 -4.1671 -4.1418 -4.1446 -4.1444 -4.1927 -4.1521 -4.1488 -4.1445\n",
       "-4.1807 -4.1393 -4.1060 -4.1003 -4.0911 -4.1053 -4.1306 -4.1612 -4.1599 -4.2131\n",
       "-4.1762 -4.1692 -4.1341 -4.1451 -4.1161 -4.1747 -4.1247 -4.2435 -4.1679 -4.1620\n",
       "-4.1441 -4.1637 -4.1382 -4.1317 -4.1296 -4.1276 -4.1505 -4.1518 -4.1720 -4.1966\n",
       "-4.1698 -4.1612 -4.1416 -4.1929 -4.1768 -4.1471 -4.1532 -4.1589 -4.1595 -4.1478\n",
       "-4.1597 -4.2054 -4.1906 -4.1894 -4.1693 -4.2063 -4.1579 -4.1574 -4.1639 -4.1046\n",
       "-4.1688 -4.1768 -4.1535 -4.1686 -4.1701 -4.1592 -4.1377 -4.1377 -4.1760 -4.1566\n",
       "-4.1884 -4.1494 -4.1615 -4.1619 -4.1678 -4.1421 -4.1824 -4.1486 -4.1779 -4.1633\n",
       "-4.1750 -4.0886 -4.1224 -4.1465 -4.2375 -4.1901 -4.1329 -4.1391 -4.0881 -4.1764\n",
       "-4.1589 -4.1652 -4.1589 -4.1510 -4.1867 -4.1780 -4.1597 -4.1307 -4.1408 -4.1857\n",
       "[torch.cuda.FloatTensor of size 64x10 (GPU 0)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating the loss on the GOU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(preds, Variable(yt).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.1609\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To zero all the gradients before update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To calculate the derivative of the loss function or the gradient of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This above calculate the gradient and learning should not be too small otherwise it will take forever to reach the \n",
    "##result and similarly not too big otherwise it will skip the minimal values.\n",
    "##This will update the learning rate and other parameters of optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, yt = next(dl)\n",
    "preds = net2(Variable(xt).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-4.1288 -4.2497 -4.0549 -4.2150 -4.1021 -4.2172 -4.1104 -4.2200 -4.2175 -4.0583\n",
       "-4.1210 -4.2142 -4.1834 -4.0215 -4.2134 -4.2144 -4.2268 -4.1475 -4.1497 -4.2017\n",
       "-4.0533 -4.2274 -4.1380 -4.2404 -4.2682 -4.2366 -4.2737 -4.1907 -4.2097 -4.1447\n",
       "-4.2071 -4.2425 -4.2611 -4.1797 -4.0662 -4.1261 -4.1347 -4.0936 -4.1538 -4.0382\n",
       "-4.2169 -4.0689 -4.2074 -4.2376 -4.1245 -4.1363 -4.1515 -4.0944 -4.1888 -4.2028\n",
       "-4.0091 -4.2516 -4.1934 -4.1552 -4.2557 -4.1480 -4.3113 -4.1268 -4.1169 -4.1200\n",
       "-4.1111 -4.2882 -4.2820 -4.2431 -4.1129 -4.1390 -4.1776 -4.0045 -4.2670 -3.9988\n",
       "-4.2411 -4.1937 -4.1876 -4.2651 -4.1111 -4.2321 -4.2327 -4.0006 -4.1188 -4.0738\n",
       "-4.0920 -4.1624 -4.1367 -4.1642 -4.0946 -4.1880 -4.0576 -4.2196 -4.1452 -4.1729\n",
       "-4.3245 -3.9054 -4.1957 -4.1861 -4.1506 -4.2180 -4.1434 -4.1287 -4.1519 -4.2287\n",
       "-3.8256 -4.4228 -4.1160 -4.1497 -4.3461 -4.1686 -4.1332 -4.1696 -4.3413 -4.0720\n",
       "-4.2182 -4.0743 -4.2085 -4.1995 -4.1863 -4.0253 -4.2418 -4.1547 -4.1402 -4.2443\n",
       "-4.1212 -4.2126 -4.1058 -4.0944 -4.1446 -4.1348 -4.1320 -4.2447 -4.1256 -4.2165\n",
       "-4.0369 -4.2572 -4.1393 -4.0854 -4.2148 -3.9553 -4.1580 -4.2190 -4.2140 -4.1985\n",
       "-4.1090 -4.2543 -4.1439 -4.0024 -4.0741 -4.1482 -4.1725 -4.2073 -4.0338 -4.1714\n",
       "-4.1481 -4.1576 -4.2124 -4.2010 -4.1352 -4.0033 -4.0837 -4.1913 -4.2093 -4.1813\n",
       "-4.2737 -4.1967 -4.2321 -4.2122 -4.0444 -4.1824 -4.1893 -4.1024 -4.2303 -4.1303\n",
       "-4.1355 -4.1888 -4.1437 -3.9912 -4.2823 -4.2547 -4.2630 -4.2122 -4.1014 -4.3138\n",
       "-4.2637 -4.0044 -4.2001 -4.1898 -4.1664 -4.2281 -4.1672 -4.0981 -4.1653 -4.1798\n",
       "-4.2103 -4.0754 -4.1660 -4.0940 -4.1740 -4.1150 -4.1853 -4.1744 -4.1209 -4.2334\n",
       "-4.2146 -4.1425 -4.1157 -4.1659 -4.2281 -4.1500 -4.1445 -4.2217 -4.1184 -4.2278\n",
       "-4.2057 -4.1416 -4.2016 -4.1623 -4.2206 -4.1885 -4.2194 -4.1392 -4.1050 -4.1694\n",
       "-4.0795 -4.2778 -4.0988 -4.1457 -4.2307 -3.9914 -4.1674 -4.1939 -4.1714 -4.1130\n",
       "-4.1433 -4.1495 -3.9836 -4.1472 -4.2372 -4.1591 -4.2466 -4.3193 -4.2424 -4.3226\n",
       "-4.1989 -4.1365 -4.1613 -4.1781 -4.0834 -4.0778 -4.0395 -4.2180 -4.1047 -4.2100\n",
       "-4.1186 -4.2554 -4.1221 -4.2242 -4.1071 -4.1736 -3.9517 -4.3017 -4.1871 -4.1177\n",
       "-4.1193 -4.2532 -4.0944 -3.9535 -4.3172 -4.2209 -4.1770 -4.1665 -4.1605 -4.2691\n",
       "-4.1054 -4.2405 -4.1839 -4.1091 -4.2425 -4.1278 -4.1507 -4.0951 -4.1829 -4.1830\n",
       "-4.0898 -4.1671 -4.1479 -4.2109 -4.1512 -4.2988 -4.0451 -4.2040 -4.1365 -4.1473\n",
       "-4.3020 -3.9507 -4.1881 -4.1983 -4.1709 -4.2180 -4.1185 -4.1110 -4.1485 -4.2192\n",
       "-4.0957 -4.1707 -4.0631 -4.1194 -4.2106 -4.1289 -4.1134 -4.2295 -4.1197 -4.2282\n",
       "-3.9756 -4.3474 -4.1906 -4.1743 -4.2665 -4.1017 -4.1205 -4.2060 -4.3422 -4.1629\n",
       "-4.3073 -3.9010 -4.1659 -4.1648 -4.1797 -4.1947 -4.1754 -4.2231 -4.1027 -4.2853\n",
       "-4.0421 -4.3267 -4.0853 -4.0364 -4.3262 -4.1057 -4.1766 -4.2821 -4.2166 -4.2121\n",
       "-4.2575 -4.1742 -4.2378 -4.2529 -4.0614 -4.2254 -4.1348 -4.0254 -4.1708 -4.0526\n",
       "-4.2944 -3.9044 -4.2081 -4.1821 -4.1334 -4.1993 -4.1274 -4.1132 -4.1609 -4.2459\n",
       "-4.1392 -4.2251 -4.0676 -4.2450 -4.2088 -4.2104 -3.9896 -4.2400 -4.2364 -4.1043\n",
       "-4.2597 -4.0728 -4.2277 -4.2091 -4.0752 -4.2311 -4.2295 -4.0402 -4.0650 -4.1598\n",
       "-3.9927 -4.2778 -4.1933 -4.0634 -4.2828 -4.1149 -4.2755 -4.1977 -4.2179 -4.1484\n",
       "-4.1323 -4.0945 -4.1493 -3.9857 -4.2270 -4.2045 -4.1588 -4.2484 -4.1808 -4.2675\n",
       "-4.1197 -4.2806 -4.2865 -4.1477 -4.0371 -4.0209 -4.1538 -4.1688 -4.0824 -4.1342\n",
       "-4.0529 -4.2623 -4.1177 -4.0414 -4.1921 -4.1416 -4.0876 -4.2147 -4.1385 -4.1967\n",
       "-4.1585 -4.1182 -4.1008 -4.2404 -4.1118 -4.1002 -4.0299 -4.2763 -4.2467 -4.1623\n",
       "-4.1811 -4.0883 -4.1189 -4.1618 -4.1650 -4.0921 -4.1095 -4.2420 -4.1357 -4.1954\n",
       "-4.1866 -4.2502 -4.2183 -4.0696 -3.9148 -4.1860 -4.1497 -4.1776 -4.1763 -4.0127\n",
       "-4.2905 -3.9333 -4.1976 -4.1844 -4.1523 -4.1523 -4.1094 -4.0981 -4.1558 -4.2590\n",
       "-4.0239 -4.2672 -4.2325 -4.1234 -4.1681 -4.0678 -4.2028 -4.1720 -4.0567 -4.0963\n",
       "-4.2120 -4.1883 -4.2788 -4.2592 -4.0013 -4.1698 -4.1738 -4.0388 -4.2013 -4.0335\n",
       "-4.2229 -4.3079 -4.3171 -4.2755 -4.2091 -4.2608 -4.2178 -3.8586 -4.2143 -4.0418\n",
       "-4.0806 -4.3161 -4.1465 -4.0219 -4.1271 -4.1366 -4.1947 -4.2640 -4.0433 -4.1382\n",
       "-4.2687 -4.1174 -3.8586 -4.2371 -4.2528 -4.2774 -4.2092 -4.2827 -4.2406 -4.1843\n",
       "-4.2030 -4.1642 -3.9950 -4.1676 -4.1775 -4.1575 -4.2393 -4.1798 -4.1883 -4.1695\n",
       "-4.2210 -4.0379 -4.1909 -4.2576 -4.1457 -4.0580 -4.1584 -4.1181 -4.2528 -4.2189\n",
       "-4.2445 -4.1164 -4.1322 -4.1930 -4.1633 -4.1886 -4.1684 -4.1246 -4.0242 -4.1669\n",
       "-4.0780 -4.1764 -4.1342 -4.1381 -4.3009 -4.2342 -4.1953 -4.1493 -4.2271 -4.2187\n",
       "-4.2889 -3.9858 -4.2047 -4.2390 -4.1310 -4.1560 -4.0961 -4.0958 -4.1231 -4.2023\n",
       "-4.1661 -4.2167 -4.2463 -4.2748 -4.0167 -4.3054 -4.2380 -4.1584 -4.0962 -4.0485\n",
       "-4.3234 -3.9506 -4.1890 -4.1833 -4.2007 -4.2556 -4.1669 -4.1201 -4.1292 -4.1991\n",
       "-4.2268 -4.2126 -4.2860 -4.1885 -3.9847 -4.1672 -4.1816 -4.1075 -4.1592 -4.0267\n",
       "-4.2505 -4.1311 -3.9010 -4.3036 -4.2037 -4.1483 -4.2177 -4.2919 -4.0803 -4.1465\n",
       "-4.2568 -4.0942 -4.1798 -4.2569 -4.1543 -4.2075 -4.2007 -3.9969 -4.2205 -4.1039\n",
       "-4.2374 -4.1651 -4.1782 -4.2249 -4.1190 -4.2414 -4.1523 -4.0354 -4.1182 -4.0604\n",
       "-4.1494 -4.0954 -4.2328 -4.0986 -4.1271 -4.0621 -4.0650 -4.2509 -4.1538 -4.2075\n",
       "-4.1092 -4.2577 -4.2627 -4.0390 -4.1155 -4.1609 -4.3011 -4.2119 -4.0685 -4.0989\n",
       "[torch.cuda.FloatTensor of size 64x10 (GPU 0)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.0242\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = loss(preds, Variable(yt).cuda())\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now completing the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.031623840332031 \t accuracy:  0.625\n",
      "loss:  3.2291362285614014 \t accuracy:  0.734375\n",
      "loss:  2.8427939414978027 \t accuracy:  0.78125\n",
      "loss:  2.9667036533355713 \t accuracy:  0.703125\n",
      "loss:  2.7820510864257812 \t accuracy:  0.765625\n",
      "loss:  2.7035868167877197 \t accuracy:  0.8125\n",
      "loss:  2.6967415809631348 \t accuracy:  0.828125\n",
      "loss:  2.697202205657959 \t accuracy:  0.875\n",
      "loss:  2.584951162338257 \t accuracy:  0.859375\n",
      "loss:  2.6495492458343506 \t accuracy:  0.84375\n"
     ]
    }
   ],
   "source": [
    "for t in range(100):\n",
    "    xt, yt = next(dl)\n",
    "    y_pred = net2(Variable(xt).cuda())\n",
    "    l = loss(y_pred, Variable(yt).cuda())\n",
    "    \n",
    "    if t % 10 == 0:\n",
    "        accuracy = np.mean(to_np(y_pred).argmax(axis=1) == to_np(yt))\n",
    "        print(\"loss: \", l.data[0], \"\\t accuracy: \", accuracy)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    l.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Taking the next min-batch. calculating the prediciton and loss and for every 10 step we are printing out the accuracy.\n",
    "##Then resetting back the gradient back to 0. Then agagin calculating the gradients and then update the weight using the\n",
    "##gradient and the learning rate.\n",
    "\n",
    "##As we go ahead in learning loss goes down and accuracy goes up.\n",
    "##Score function for the calculation of score on predicted values. Count function to count the length of iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x, y):\n",
    "    y_pred = to_np(net2(V(x)))\n",
    "    return np.sum(y_pred.argmax(axis=1) == to_np(y))/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(iter, key=None):\n",
    "    if key:\n",
    "        if callable(key):\n",
    "            return sum(bool(key(x)) for x in iter)\n",
    "        return sum(x == key for x in iter)\n",
    "    try:\n",
    "        return len(iter)\n",
    "    except TypeError:\n",
    "        return sum(1 for _ in iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = count(md.trn_dl)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = count(md.val_dl)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combinig all the things we get the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9037619426751592\n"
     ]
    }
   ],
   "source": [
    "net2 = LogReg().cuda()\n",
    "loss=nn.NLLLoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer=optim.SGD(net2.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1):  ##Epoch number of time we are going to process the complete dataset\n",
    "    losses=[]\n",
    "    dl = iter(md.trn_dl)\n",
    "    for t in range(0,k):\n",
    "        # Forward pass: compute predicted y and loss by passing x to the model.\n",
    "        xt, yt = next(dl)\n",
    "        y_pred = net2(V(xt))\n",
    "        l = loss(y_pred, V(yt))\n",
    "        losses.append(l)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable weights of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        l.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    val_dl = iter(md.val_dl)\n",
    "    val_scores = [score(*next(val_dl)) for i in range(0,157)]\n",
    "    print(np.mean(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now we are going to code the optimizer by ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "##So we have already define the layer of our neural net and also the loss function and learning rate.\n",
    "##Now since we are going to write the optimizer which update the bias and weight after a iteration through each min-batch\n",
    "##For l.backward() we are taking the tensor value and then we are substracting the gradient of tensor * learning rate\n",
    "##from the original tensor value. In this way l.backward works and for optimizer.zero_grad() we are putting gradient \n",
    "##value back to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9019705414012739\n"
     ]
    }
   ],
   "source": [
    "net2 = LogReg().cuda()  \n",
    "loss_fn=nn.NLLLoss()\n",
    "lr = 1e-2\n",
    "w,b = net2.l1_w,net2.l1_b    ##weight and bias value from LogReg() function\n",
    "\n",
    "for epoch in range(1):\n",
    "    losses=[]\n",
    "    dl = iter(md.trn_dl)\n",
    "    for t in range(0,k):\n",
    "        xt, yt = next(dl)\n",
    "        y_pred = net2(V(xt))\n",
    "        l = loss(y_pred, Variable(yt).cuda())\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        l.backward()                                       ##calculating the gradient value of weight, and bias\n",
    "        w.data -= w.grad.data * lr                         ##updating the weight value (tensor update)\n",
    "        b.data -= b.grad.data * lr                         ##updating the bias value \n",
    "        \n",
    "        w.grad.data.zero_()                                ##Putting the value of gradient equal to zero. \n",
    "        b.grad.data.zero_()   \n",
    "\n",
    "    val_dl = iter(md.val_dl)\n",
    "    val_scores = [score(*next(val_dl)) for i in range(0,m)]\n",
    "    print(np.mean(val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR FIT FUNCTION IS-\n",
    "\n",
    "    for epoch in range(1):\n",
    "        losses=[]\n",
    "        dl = iter(md.trn_dl)\n",
    "        for t in range(0,k):\n",
    "            xt, yt = next(dl)\n",
    "            y_pred = net2(V(xt))\n",
    "            l = loss(y_pred, Variable(yt).cuda())\n",
    "            losses.append(loss)\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            l.backward()                                       ##calculating the gradient value of weight, and bias\n",
    "            w.data -= w.grad.data * lr                         ##updating the weight value (tensor update)\n",
    "            b.data -= b.grad.data * lr                         ##updating the bias value \n",
    "\n",
    "            w.grad.data.zero_()                                ##Putting the value of gradient equal to zero. \n",
    "            b.grad.data.zero_()   \n",
    "\n",
    "        val_dl = iter(md.val_dl)\n",
    "        val_scores = [score(*next(val_dl)) for i in range(0,m)]\n",
    "        print(np.mean(val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR optimizer.step() IS - \n",
    "\n",
    "        w.data -= w.grad.data * lr                         ##updating the weight value (tensor update)\n",
    "        b.data -= b.grad.data * lr                         ##updating the bias value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l.backward() is remain same as l.backward() and is used for calculating gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR optimizer.zero_grad() IS -\n",
    "\n",
    "        w.grad.data.zero_()                                ##Putting the value of gradient equal to zero. \n",
    "        b.grad.data.zero_() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR CALCULATING LOSS - \n",
    "\n",
    "        l = loss(y_pred, Variable(yt).cuda())\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR LogSoftmax() IS -\n",
    "    \n",
    "    x = torch.log(torch.exp(x)/torch.exp(x).sum(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR Linear() IS -\n",
    "\n",
    "    x = torch.matmul(x, self.l1_w) + self.l1_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
